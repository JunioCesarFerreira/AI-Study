# Análise de Complexidade e notação big O

Cientistas da computação frequentemente se deparam com a tarefa de comparar algoritmos para ver o quão rápido eles rodam ou quanta memória eles requerem. Existem duas abordagens para essa tarefa. A primeira é a execução comparativa (**benchmarking**) - executando os algoritmos em um computador e medindo a velocidade em segundos e o consumo de memória em bytes. No final das contas, é isso que realmente importa, mas uma execução comparativa pode ser insatisfatória por ser tão específica: ela mede o desempenho de um programa específico escrito em uma linguagem específica, rodando em um computador específico, com um compilador específico e dados de entrada específicos. A partir do resultado único que a execução comparativa fornece, pode ser difícil prever como o algoritmo se sairia em um compilador, computador ou conjunto de dados diferente. A segunda abordagem baseia-se em uma análise matemática de algoritmos, independentemente da implementação e entrada específica, conforme discutido abaixo.

## Notação Big O

A notação *Big O* é uma ferramenta matemática utilizada para classificar o comportamento assintótico de funções, ou seja, como elas se comportam quando seus argumentos se aproximam do infinito. Ela é particularmente útil na análise de algoritmos, onde nos interessa a eficiência computacional à medida que o tamanho da entrada aumenta.

### Definição Formal

Seja $f$ e $g$ duas funções reais definidas em um conjunto não vazio $S\subset\mathbb{R}$. Dizemos que *f de n é big O de g de n* e denotamos $f(n) = O\big(g_n\big)$ se existir uma constante positiva $c$ tal que:

$$0 \le f(n) \le c g(n)$$

para todo $n \in S$ tal que $n \ge n_0$, sendo $n_0$ é um número real positivo.

### Interpretação

A notação $f(n) = O\big(g_n\big)$ indica que o crescimento de $f(n)$ é, no pior caso, comparável ao de $g(n)$ quando $n$ se aproxima do infinito. Ou seja, existe um limite superior para o quão rápido $f(n)$ pode crescer em relação a $g(n)$.

### Propriedades

1. **Transitividade**

    Se $f(n)=O(g(n))$ e $g(n)=O(h(n))$ então $f(n)=O(h(n))$.

2. **Homogeneidade**

    Se $f(n)=O(g(n))$ e $c$ é uma constante, então $cf(n)=O(g(n))$.

3. **Aditividade**

    Se $f(n)=O(g(n))$ e $h(n)=O(k(n))$, então $f(n)+h(n)=O(g(n)+h(n))$.

4. **Multiplicidade**

    Se $f(n)=O(g(n))$ e $h(n)=O(k(n))$, então $f(n)h(n)=O(g(n)k(n))$.

*Demonstração:*

Apenas para deixar a notação menos carregada, utilizaremos $f_n$ para denotar a função $f(n)$.

**1. Transitividade:**

Se $f_n = O(g_n)$ e $g_n = O(h_n)$, então para todo $n \ge n_0$, existe uma constante $c_0$ tal que $0 \le f_n \le c_0 g_n$ e para todo $n \ge n_1$, existe uma constante $c_1$ tal que $0 \le g_n \le c_1 h_n$.

Considere $n_2=\max(n_0,n_1)$ e $c_2=c_0 c_1$ desta forma obtemos:

$$0 \le f_n \le c_1 g_n \le c_2 h_n, \forall n\ge n_2.$$

**2. Homogeneidade:**

Se $f_n = O(g_n)$, então para todo $n \ge n_0$, existe uma constante $c_0$ tal que $f_n \le c_0 g_n$. Multiplicando ambos os lados por $c$, obtemos:

$$0 \le c f_n \le c c_0 g_n.$$

Assim, para $n \ge n_0$, $cf_n = O(g_n)$ com a constante $c c_0$.

**3. Aditividade:**

Se $f_n = O(g_n)$ e $h_n = O(k_n)$, então para todo $n \ge n_0$, existe uma constante $c_0$ tal que $0 \le f_n \le c_0 g_n$ e para todo $n \ge n_1$, existe uma constante $c_1$ tal que $0 \le h_n \le c_1 k_n$. Somando as duas desigualdades, obtemos:

$$0 \le f_n + h_n \le c_0 g_n + c_1 k_n.$$

Assim, para $n \ge max(n_0, n_1)$, $f_n + h_n = O(g_n + k_n)$ com a constante $c = max(c_0, c_1)$. Pois,

$$0 \le f_n + h_n \le c_0 g_n + c_1 k_n \le c g_n+h_n.$$

**4. Multiplicidade**

Dado que $f_n = O(g_n)$, existem constantes $c_0$ e $n_0$ tais que $0 \leq f_n \leq c_0 g_n$ para todo $n \geq n_0$. E $h_n = O(k_n)$ implica que existem constantes $c_1$ e $n_1$ tais que $0 \leq h_n \leq c_1 k_n$ para todo $n \geq n_1$. Assim, para $n \geq \max(n_0, n_1)$, temos $0 \leq f_n h_n \leq c_1 c_2 g_n k_n$, o que demonstra que $f_n h_n = O(g_n k_n)$.
